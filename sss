from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType
from pyspark.sql.functions import lit
from datetime import datetime

spark = SparkSession.builder.getOrCreate()

# === CONFIGURATION ===
CATALOG_TO_MONITOR = "prod"
PERMISSION_TABLE = "grant.audit.access_report"
TIMESTAMP_FORMAT = "%Y-%m-%dT%H:%M:%SZ"

# === DEFINE SCHEMA EXPLICITLY ===
schema = StructType([
    StructField("catalog_name", StringType(), True),
    StructField("schema_name", StringType(), True),
    StructField("table_name", StringType(), True),
    StructField("access_group", StringType(), True),
    StructField("privilege_type", StringType(), True),
    StructField("table_type", StringType(), True),
    StructField("access_level", StringType(), True),
])

# === COLLECT PERMISSIONS ===
schemas = [row.databaseName for row in spark.sql(f"SHOW SCHEMAS IN {CATALOG_TO_MONITOR}").collect()]
permissions_data = []

for schema_name in schemas:
    tables = spark.sql(f"SHOW TABLES IN {CATALOG_TO_MONITOR}.{schema_name}").collect()

    for table in tables:
        table_name = table.tableName
        full_table_name = f"{CATALOG_TO_MONITOR}.{schema_name}.{table_name}"

        # Get table_type using DESCRIBE FORMATTED
        try:
            table_info = spark.sql(f"DESCRIBE FORMATTED {full_table_name}").collect()
            table_type = None
            for row in table_info:
                if row.col_name.strip().lower() == "type":
                    table_type = row.data_type.strip()
                    break
        except:
            table_type = "UNKNOWN"

        # Get grants
        try:
            grants = spark.sql(f"SHOW GRANTS ON TABLE {full_table_name}").collect()
        except:
            continue  # Skip if grants can't be retrieved

        for grant in grants:
            permissions_data.append((
                CATALOG_TO_MONITOR,
                schema_name,
                table_name,
                grant["Principal"],
                grant["ActionType"],
                table_type,
                grant["ObjectKey"]
            ))

# Create DataFrame with schema
current_df = spark.createDataFrame(permissions_data, schema=schema)

# Add timestamp to new entries only if there are changes
from pyspark.sql.utils import AnalysisException

try:
    existing_df = spark.table(PERMISSION_TABLE)
except AnalysisException:
    # Table does not exist — create it with the first run
    timestamp = datetime.utcnow().strftime(TIMESTAMP_FORMAT)
    current_df = current_df.withColumn("updated_at", lit(timestamp))
    current_df.write.format("delta").mode("overwrite").saveAsTable(PERMISSION_TABLE)
    print(f"✅ Created permission tracking table: {PERMISSION_TABLE}")
    exit()

# Columns for comparison (without timestamp)
compare_cols = ["catalog_name", "schema_name", "table_name", "access_group", "privilege_type", "table_type", "access_level"]

existing_clean = existing_df.select(compare_cols)
new_clean = current_df.select(compare_cols)

# Find new or changed permission entries
new_changes_df = new_clean.subtract(existing_clean)

if new_changes_df.count() > 0:
    timestamp = datetime.utcnow().strftime(TIMESTAMP_FORMAT)
    changes_with_ts = new_changes_df.withColumn("updated_at", lit(timestamp))
    changes_with_ts.write.format("delta").mode("append").saveAsTable(PERMISSION_TABLE)
    print(f"✅ {new_changes_df.count()} permission changes recorded at {timestamp}")
else:
    print("ℹ️ No permission changes detected.")
