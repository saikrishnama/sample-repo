from pyspark.sql import SparkSession
from pyspark.sql.functions import lit
from datetime import datetime

spark = SparkSession.builder.getOrCreate()

# === CONFIGURATION ===
CATALOG_TO_MONITOR = "prod"  # Catalog name (e.g., prod)
PERMISSION_TABLE = "grant.audit.access_report"
TIMESTAMP_FORMAT = "%Y-%m-%dT%H:%M:%SZ"

# === COLLECT PERMISSIONS ===
schemas = [row.databaseName for row in spark.sql(f"SHOW SCHEMAS IN {CATALOG_TO_MONITOR}").collect()]
permissions_data = []

# Gather current permissions
for schema in schemas:
    tables = spark.sql(f"SHOW TABLES IN {CATALOG_TO_MONITOR}.{schema}").collect()
    for table in tables:
        table_name = table.tableName
        full_table_name = f"{CATALOG_TO_MONITOR}.{schema}.{table_name}"

        # Get table type using DESCRIBE FORMATTED
        table_info = spark.sql(f"DESCRIBE FORMATTED {full_table_name}").collect()
        table_type = None
        for row in table_info:
            if "Type" in row:
                table_type = row[1]
                break

        # Fetch grants for the table
        try:
            grants = spark.sql(f"SHOW GRANTS ON TABLE {full_table_name}").collect()
        except:
            continue  # Skip if the table is inaccessible

        # Collect data for each grant
        for grant in grants:
            permissions_data.append((
                CATALOG_TO_MONITOR,           # catalog_name
                schema,                       # schema_name
                table_name,                   # table_name
                grant.Principal,              # access_group
                grant.ActionType,             # privilege_type
                table_type,                   # table_type
                grant.ObjectKey               # access_level (column-level or row-level)
            ))

columns = ["catalog_name", "schema_name", "table_name", "access_group", "privilege_type", "table_type", "access_level"]
current_df = spark.createDataFrame(permissions_data, columns)

# === CREATE TABLE IF NOT EXISTS ===
if not spark._jsparkSession.catalog().tableExists(PERMISSION_TABLE):
    # Define the schema for the access report table
    schema = current_df.schema.add("updated_at", "string")  # Add the updated_at column
    
    # Create the table
    current_df.write.format("delta").option("path", "/mnt/grant/audit/access_report").saveAsTable(PERMISSION_TABLE)
    print(f"Created table {PERMISSION_TABLE} in the grant.audit catalog.")

# === LOAD EXISTING PERMISSION SNAPSHOT ===
existing_df = spark.table(PERMISSION_TABLE).select(columns + ["updated_at"])  # Include updated_at for comparison

# === FIND NEW/CHANGED PERMISSIONS ===
new_entries_df = current_df.subtract(existing_df.drop("updated_at"))

# === APPEND ONLY NEW ENTRIES WITH TIMESTAMP ===
if new_entries_df.count() > 0:
    timestamp = datetime.utcnow().strftime(TIMESTAMP_FORMAT)
    new_entries_df = new_entries_df.withColumn("updated_at", lit(timestamp))
    new_entries_df.write.format("delta").mode("append").saveAsTable(PERMISSION_TABLE)
    print(f"[{timestamp}] Appended {new_entries_df.count()} new permission entries.")
else:
    print("No new permission entries found.")
